{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理\n",
    "转换为csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zl_classify\n",
    "import imp\n",
    "imp.reload(zl_classify)\n",
    "from zl_classify import load_data_csvs,MLP_softmax,MLP_sigmoid\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from ufy.HX.diagnosis.classify import joblib\n",
    "import keras\n",
    "from ufy.HX.diagnosis.classify import KNN\n",
    "from ufy.HX.diagnosis.classify import plot_roc_curve\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,confusion_matrix\n",
    "from ufy.HX.diagnosis.classify import RandomForest\n",
    "from ufy.HX.diagnosis.classify import plot_roc_curve\n",
    "from ufy.HX.diagnosis.classify import XGboost\n",
    "from zl_classify import MLP_softmax\n",
    "from ufy.HX.diagnosis.classify import min_max_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data = 'train_data_name'\n",
    "test_name = 'test_data_name'\n",
    "data = pd.read_excel('train_data.xlsx',sheet_name='train_data')\n",
    "test_data = pd.read_excel('test_data.xlsx',sheet_name='test_data')\n",
    "data.to_csv(name_data+'.csv',index=False)\n",
    "test_data.to_csv(test_name+'.csv',index=False)\n",
    "labels = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data: TYY4data_22-03-23.csv\n",
      "((1679, 478), (1679, 1)) ((187, 478), (187, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载并划分数据集\n",
    "filenames = [name_data+'.csv']\n",
    "(x_train,y_train),(x_test,y_test) = load_data_csvs(filenames,\n",
    "                                                  target_cols=1,# 最后一列是标签\n",
    "                                                  drop_id=True,\n",
    "                                                  id_cols=1,# 前面三列是无关特征\n",
    "                                                  split_rate=0.6,\n",
    "                                                  shuffle=True)\n",
    "print((x_train.shape,y_train.shape),(x_test.shape,y_test.shape))\n",
    "input_shape = x_train.shape[1]\n",
    "def metrics_model(y_true,y_pre_cls,model_name,labels):\n",
    "    acc = accuracy_score(y_true,y_pre_cls)\n",
    "    prec = precision_score(y_true,y_pre_cls,average=None)\n",
    "    f1 = f1_score(y_true,y_pre_cls,average=None)\n",
    "    rec = recall_score(y_true,y_pre_cls,average=None)\n",
    "    cof_met = confusion_matrix(y_true,y_pre_cls,labels=labels)\n",
    "    result = {\n",
    "        '模型':model_name,\n",
    "        '准确率':acc,\n",
    "        '精确率':prec,\n",
    "        'F1':f1,\n",
    "        '召回率':rec,\n",
    "        '混淆矩阵':cof_met\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Anaconda\\lib\\site-packages\\ufy\\HX\\diagnosis\\classify.py:226: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_train, y_train)\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:40:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(261, 1)\n",
      "(261, 1, 3)\n",
      "(261, 3)\n",
      "Epoch 1/10000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0485 - acc: 0.9952 - val_loss: 1.9171 - val_acc: 0.8113\n",
      "Epoch 2/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0688 - acc: 0.9808 - val_loss: 2.7301 - val_acc: 0.8302\n",
      "Epoch 3/10000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7.4446e-07 - acc: 1.0000 - val_loss: 3.7491 - val_acc: 0.8302\n",
      "Epoch 4/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 3.6913 - val_acc: 0.8302\n",
      "Epoch 5/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0137 - acc: 0.9952 - val_loss: 2.8076 - val_acc: 0.8302\n",
      "Epoch 6/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.1278e-04 - acc: 1.0000 - val_loss: 2.2570 - val_acc: 0.8491\n",
      "Epoch 7/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0365 - acc: 0.9952 - val_loss: 2.6528 - val_acc: 0.8491\n",
      "Epoch 8/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.7691e-04 - acc: 1.0000 - val_loss: 3.1736 - val_acc: 0.8302\n",
      "Epoch 9/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.4753e-05 - acc: 1.0000 - val_loss: 3.6252 - val_acc: 0.8302\n",
      "Epoch 10/10000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0802 - acc: 0.9952 - val_loss: 3.8486 - val_acc: 0.8302\n",
      "Epoch 11/10000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0288 - acc: 0.9952 - val_loss: 3.5278 - val_acc: 0.8302\n"
     ]
    }
   ],
   "source": [
    "x_train_normal = min_max_normal(x_train)\n",
    "x_test_normal = min_max_normal(x_test)\n",
    "y_true = y_test[:, 0]\n",
    "model_path = 'model_weights/'+name_data+'/'\n",
    "if os.path.exists(model_path) == False:\n",
    "    os.makedirs(model_path)\n",
    "total_result = pd.DataFrame(columns=['模型','准确率','精确率','F1','召回率','混淆矩阵'])\n",
    "\n",
    "# KNN\n",
    "knn = sk.neighbors.KNeighborsClassifier()\n",
    "y_score = knn.fit(x_train,y_train)\n",
    "y_pre_cls = knn.predict(x_test)\n",
    "joblib.dump(knn, model_path+'knn.pkl')\n",
    "result = metrics_model(y_true,y_pre_cls,'knn',labels)\n",
    "total_result = total_result.append(result,ignore_index=True)\n",
    "\n",
    "# Random Forest\n",
    "model_path = 'model_weights/'+name_data+'/RandomForest.pkl'\n",
    "rdfcls = RandomForest(x_train,y_train,model_savepath=model_path,istraining=True)\n",
    "y_pre = rdfcls.predict_proba(x_test)[:,1]\n",
    "y_pre_cls = rdfcls.predict(x_test)\n",
    "result = metrics_model(y_true,y_pre_cls,'randomforest',labels)\n",
    "total_result = total_result.append(result,ignore_index=True)\n",
    "\n",
    "# XGBoost\n",
    "model_path = 'model_weights/'+name_data+'/xgboost.pkl'\n",
    "xgbc = XGboost(x_train,y_train,model_savepath=model_path,istraining=True)\n",
    "y_pre = xgbc.predict_proba(x_test)\n",
    "# print('y_pre:',y_pre)\n",
    "y_pre_cls = xgbc.predict(x_test)\n",
    "# print('y_cls:',y_pre_cls)\n",
    "\n",
    "result = metrics_model(y_true,y_pre_cls,'xgboost',labels)\n",
    "total_result = total_result.append(result,ignore_index=True)\n",
    "\n",
    "\n",
    "# MLP_softmax\n",
    "model_path = 'model_weights/'+name_data+'/MLP_softmax.h5'\n",
    "mlp_softmax = MLP_softmax(x_train,y_train,model_savepath=model_path,istraining=True,batch_size=64,validation_split=0.2,class_num=len(labels),shape_in=input_shape)\n",
    "y_pre_cls = mlp_softmax.predict(x_test)\n",
    "y_pre_cls = np.argmax(y_pre_cls,axis=-1)\n",
    "result = metrics_model(y_true,y_pre_cls,'MLP',labels)\n",
    "total_result = total_result.append(result,ignore_index=True)\n",
    "total_result.to_excel('result_'+name_data+'.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data: TYY4test_22-03-23.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1679, 478), (1679, 1)) ((13986, 478), (13986, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载并划分数据集\n",
    "filenames = [test_name+'.csv']\n",
    "undepend_test_data = pd.read_csv(filenames[0])\n",
    "(_,_),(x_test,y_test) = load_data_csvs(filenames,\n",
    "                                                  target_cols=1,# 最后一列是标签\n",
    "                                                  drop_id=True,\n",
    "                                                  id_cols=1,# 前面一列是无关特征\n",
    "                                                  split_rate=0,\n",
    "                                                  shuffle=False)\n",
    "print((x_train.shape,y_train.shape),(x_test.shape,y_test.shape))\n",
    "input_shape = x_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "C:\\Anaconda\\lib\\site-packages\\ufy\\HX\\diagnosis\\classify.py:226: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_train, y_train)\n",
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python38\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:43:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1679, 1)\n",
      "(1679, 1, 4)\n",
      "(1679, 4)\n",
      "Epoch 1/10000\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.1451 - acc: 0.9531 - val_loss: 0.1214 - val_acc: 0.9732\n",
      "Epoch 2/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0682 - acc: 0.9792 - val_loss: 0.0762 - val_acc: 0.9792\n",
      "Epoch 3/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0481 - acc: 0.9836 - val_loss: 0.0934 - val_acc: 0.9732\n",
      "Epoch 4/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0433 - acc: 0.9829 - val_loss: 0.0981 - val_acc: 0.9702\n",
      "Epoch 5/10000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0543 - acc: 0.9784 - val_loss: 0.1285 - val_acc: 0.9702\n",
      "Epoch 6/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0440 - acc: 0.9859 - val_loss: 0.0819 - val_acc: 0.9762\n",
      "Epoch 7/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0300 - acc: 0.9888 - val_loss: 0.0836 - val_acc: 0.9792\n",
      "Epoch 8/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0195 - acc: 0.9940 - val_loss: 0.1106 - val_acc: 0.9732\n",
      "Epoch 9/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0242 - acc: 0.9896 - val_loss: 0.1094 - val_acc: 0.9762\n",
      "Epoch 10/10000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0154 - acc: 0.9948 - val_loss: 0.1039 - val_acc: 0.9762\n",
      "Epoch 11/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0199 - acc: 0.9948 - val_loss: 0.1101 - val_acc: 0.9792\n",
      "Epoch 12/10000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0237 - acc: 0.9911 - val_loss: 0.2528 - val_acc: 0.9613\n",
      "Epoch 13/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0383 - acc: 0.9888 - val_loss: 0.1367 - val_acc: 0.9732\n",
      "Epoch 14/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0258 - acc: 0.9911 - val_loss: 0.1261 - val_acc: 0.9732\n",
      "Epoch 15/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0204 - acc: 0.9933 - val_loss: 0.1151 - val_acc: 0.9792\n",
      "Epoch 16/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.1180 - val_acc: 0.9792\n",
      "Epoch 17/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0167 - acc: 0.9940 - val_loss: 0.1345 - val_acc: 0.9762\n",
      "Epoch 18/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0109 - acc: 0.9948 - val_loss: 0.1531 - val_acc: 0.9732\n",
      "Epoch 19/10000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0170 - acc: 0.9948 - val_loss: 0.1297 - val_acc: 0.9792\n",
      "Epoch 20/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0133 - acc: 0.9948 - val_loss: 0.1202 - val_acc: 0.9762\n",
      "Epoch 21/10000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0126 - acc: 0.9955 - val_loss: 0.1140 - val_acc: 0.9732\n",
      "Epoch 22/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0144 - acc: 0.9955 - val_loss: 0.1283 - val_acc: 0.9762\n",
      "Epoch 23/10000\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.1074 - val_acc: 0.9821\n",
      "Epoch 24/10000\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0123 - acc: 0.9955 - val_loss: 0.1086 - val_acc: 0.9792\n"
     ]
    }
   ],
   "source": [
    "# x_train_normal = min_max_normal(x_train)\n",
    "x_test_normal = min_max_normal(x_test)\n",
    "y_true = y_test[:, 0]\n",
    "model_path = 'model_weights/'+name_data+'/'\n",
    "if os.path.exists(model_path) == False:\n",
    "    os.makedirs(model_path)\n",
    "total_result = pd.DataFrame(columns=['模型','准确率','精确率','F1','召回率','混淆矩阵'])\n",
    "\n",
    "# KNN\n",
    "knn = sk.neighbors.KNeighborsClassifier()\n",
    "y_score = knn.fit(x_train,y_train)\n",
    "y_pre_cls = knn.predict(x_test)\n",
    "joblib.dump(knn, model_path+'knn.pkl')\n",
    "result = metrics_model(y_true,y_pre_cls,'knn',labels)\n",
    "total_result = total_result.append(result,ignore_index=True)\n",
    "\n",
    "# Random Forest\n",
    "model_path = 'model_weights/'+name_data+'/RandomForest.pkl'\n",
    "rdfcls = RandomForest(x_train,y_train,model_savepath=model_path,istraining=True)\n",
    "y_pre = rdfcls.predict_proba(x_test)[:,1]\n",
    "y_pre_cls = rdfcls.predict(x_test)\n",
    "result = metrics_model(y_true,y_pre_cls,'randomforest',labels)\n",
    "total_result = total_result.append(result,ignore_index=True)\n",
    "\n",
    "# XGBoost\n",
    "model_path = 'model_weights/'+name_data+'/xgboost.pkl'\n",
    "xgbc = XGboost(x_train,y_train,model_savepath=model_path,istraining=True)\n",
    "# y_pre = xgbc.predict_proba(x_test)[:,1]\n",
    "y_pre = xgbc.predict_proba(x_test)\n",
    "undepend_test_data['xgboost_pred_proba0'] = y_pre[:,0]\n",
    "undepend_test_data['xgboost_pred_proba1'] = y_pre[:,1]\n",
    "undepend_test_data['xgboost_pred_proba2'] = y_pre[:,2]\n",
    "undepend_test_data['xgboost_pred_proba3'] = y_pre[:,3]\n",
    "y_pre_cls = xgbc.predict(x_test)\n",
    "undepend_test_data['xgboost_pred'] = y_pre_cls\n",
    "result = metrics_model(y_true,y_pre_cls,'xgboost',labels)\n",
    "total_result = total_result.append(result,ignore_index=True)\n",
    "\n",
    "\n",
    "# MLP_softmax\n",
    "model_path = 'model_weights/'+name_data+'/MLP_softmax.h5'\n",
    "mlp_softmax = MLP_softmax(x_train,y_train,model_savepath=model_path,istraining=True,batch_size=64,validation_split=0.2,class_num=len(labels),shape_in=input_shape)\n",
    "y_pre_cls = mlp_softmax.predict(x_test)\n",
    "y_pre_cls = np.argmax(y_pre_cls,axis=-1)\n",
    "result = metrics_model(y_true,y_pre_cls,'MLP',labels)\n",
    "total_result = total_result.append(result,ignore_index=True)\n",
    "total_result.to_excel('result_'+test_name+'.xlsx')\n",
    "undepend_test_data.to_excel('xgboost_result_'+test_name+'.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28311256, 0.08236288, 0.6345245 ],\n",
       "       [0.68077374, 0.28495133, 0.0342749 ],\n",
       "       [0.7063562 , 0.08121357, 0.21243024],\n",
       "       ...,\n",
       "       [0.18981019, 0.6475031 , 0.16268672],\n",
       "       [0.06001392, 0.6394642 , 0.30052185],\n",
       "       [0.0676529 , 0.654036  , 0.27831113]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
